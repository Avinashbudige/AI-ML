{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Introduction to Neural Networks with TensorFlow and PyTorch\n",
        "\n",
        "This notebook demonstrates fundamental neural network concepts using both TensorFlow/Keras and PyTorch.\n",
        "\n",
        "## Sections:\n",
        "1. Perceptron from Scratch\n",
        "2. Multi-Layer Perceptron with NumPy\n",
        "3. Keras Neural Network\n",
        "4. PyTorch Neural Network\n",
        "5. Model Evaluation\n",
        "6. Model Deployment (SavedModel, TorchScript, TFLite, ONNX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "print(f'TensorFlow version: {tf.__version__}')\n",
        "print(f'PyTorch version: {torch.__version__}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Perceptron from Scratch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Perceptron:\n",
        "    \"\"\"Simple perceptron for binary classification\"\"\"\n",
        "    def __init__(self, learning_rate=0.01, n_iterations=1000):\n",
        "        self.lr = learning_rate\n",
        "        self.n_iter = n_iterations\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "        self.weights = np.zeros(n_features)\n",
        "        self.bias = 0\n",
        "        \n",
        "        for _ in range(self.n_iter):\n",
        "            for idx, x_i in enumerate(X):\n",
        "                linear_output = np.dot(x_i, self.weights) + self.bias\n",
        "                y_predicted = self._activation(linear_output)\n",
        "                update = self.lr * (y[idx] - y_predicted)\n",
        "                self.weights += update * x_i\n",
        "                self.bias += update\n",
        "    \n",
        "    def predict(self, X):\n",
        "        linear_output = np.dot(X, self.weights) + self.bias\n",
        "        return self._activation(linear_output)\n",
        "    \n",
        "    def _activation(self, x):\n",
        "        return np.where(x >= 0, 1, 0)\n",
        "\n",
        "# Test the perceptron\n",
        "X_simple, y_simple = make_classification(n_samples=100, n_features=2, n_redundant=0, \n",
        "                                         n_informative=2, random_state=42, n_clusters_per_class=1)\n",
        "perceptron = Perceptron(learning_rate=0.1, n_iterations=100)\n",
        "perceptron.fit(X_simple, y_simple)\n",
        "predictions = perceptron.predict(X_simple)\n",
        "print(f'Perceptron Accuracy: {accuracy_score(y_simple, predictions):.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Multi-Layer Perceptron with NumPy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-np.clip(x, -500, 500)))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "class NumpyMLP:\n",
        "    \"\"\"Simple MLP with one hidden layer using NumPy\"\"\"\n",
        "    def __init__(self, input_size, hidden_size, output_size, learning_rate=0.1):\n",
        "        self.lr = learning_rate\n",
        "        self.W1 = np.random.randn(input_size, hidden_size) * 0.01\n",
        "        self.b1 = np.zeros((1, hidden_size))\n",
        "        self.W2 = np.random.randn(hidden_size, output_size) * 0.01\n",
        "        self.b2 = np.zeros((1, output_size))\n",
        "    \n",
        "    def forward(self, X):\n",
        "        self.z1 = np.dot(X, self.W1) + self.b1\n",
        "        self.a1 = sigmoid(self.z1)\n",
        "        self.z2 = np.dot(self.a1, self.W2) + self.b2\n",
        "        self.a2 = sigmoid(self.z2)\n",
        "        return self.a2\n",
        "    \n",
        "    def backward(self, X, y):\n",
        "        m = X.shape[0]\n",
        "        dz2 = self.a2 - y.reshape(-1, 1)\n",
        "        dW2 = np.dot(self.a1.T, dz2) / m\n",
        "        db2 = np.sum(dz2, axis=0, keepdims=True) / m\n",
        "        dz1 = np.dot(dz2, self.W2.T) * sigmoid_derivative(self.a1)\n",
        "        dW1 = np.dot(X.T, dz1) / m\n",
        "        db1 = np.sum(dz1, axis=0, keepdims=True) / m\n",
        "        \n",
        "        self.W2 -= self.lr * dW2\n",
        "        self.b2 -= self.lr * db2\n",
        "        self.W1 -= self.lr * dW1\n",
        "        self.b1 -= self.lr * db1\n",
        "    \n",
        "    def train(self, X, y, epochs=1000):\n",
        "        for epoch in range(epochs):\n",
        "            output = self.forward(X)\n",
        "            self.backward(X, y)\n",
        "            if epoch % 200 == 0:\n",
        "                loss = np.mean((output - y.reshape(-1, 1)) ** 2)\n",
        "                print(f'Epoch {epoch}, Loss: {loss:.4f}')\n",
        "\n",
        "# Test NumPy MLP\n",
        "numpy_mlp = NumpyMLP(input_size=2, hidden_size=4, output_size=1, learning_rate=0.5)\n",
        "numpy_mlp.train(X_simple, y_simple, epochs=1000)\n",
        "numpy_predictions = (numpy_mlp.forward(X_simple) > 0.5).astype(int).flatten()\n",
        "print(f'NumPy MLP Accuracy: {accuracy_score(y_simple, numpy_predictions):.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Keras Neural Network\n\n### Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate a more complex dataset for Keras and PyTorch\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, \n",
        "                          n_redundant=5, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(f'Training set shape: {X_train_scaled.shape}')\n",
        "print(f'Test set shape: {X_test_scaled.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Build and Train Keras Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build Keras model\n",
        "model_keras = keras.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=(20,)),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model_keras.compile(optimizer='adam',\n",
        "                   loss='binary_crossentropy',\n",
        "                   metrics=['accuracy'])\n",
        "\n",
        "print(model_keras.summary())\n",
        "\n",
        "# Train the model\n",
        "history = model_keras.fit(X_train_scaled, y_train,\n",
        "                         epochs=50,\n",
        "                         batch_size=32,\n",
        "                         validation_split=0.2,\n",
        "                         verbose=0)\n",
        "\n",
        "print(f'\\nFinal training accuracy: {history.history[\"accuracy\"][-1]:.4f}')\n",
        "print(f'Final validation accuracy: {history.history[\"val_accuracy\"][-1]:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save Keras Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save model in SavedModel format\n",
        "saved_model_dir = 'keras_saved_model'\n",
        "model_keras.save(saved_model_dir, include_optimizer=False)\n",
        "print(f'Saved Keras model to {saved_model_dir}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === TFLite conversion and simple inference example ===\n",
        "# NEW CELL ADDED: TFLite export for edge deployment\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "saved_model_dir = 'keras_saved_model'\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
        "# Optional optimizations for edge: default optimize, float16 quant, or full integer quant\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "# Example: allow float16 quantization (works well on many edge devices)\n",
        "converter.target_spec.supported_types = [tf.float16]\n",
        "\n",
        "try:\n",
        "    tflite_model = converter.convert()\n",
        "    tflite_path = 'keras_model.tflite'\n",
        "    with open(tflite_path, 'wb') as f:\n",
        "        f.write(tflite_model)\n",
        "    print('Saved TFLite model to', tflite_path)\n",
        "\n",
        "    # Run a quick inference using the TFLite interpreter\n",
        "    interpreter = tf.lite.Interpreter(model_path=tflite_path)\n",
        "    interpreter.allocate_tensors()\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "\n",
        "    # Create a dummy input with correct shape\n",
        "    input_shape = input_details[0]['shape']\n",
        "    dummy_input = np.random.randn(*[dim if dim != -1 else 1 for dim in input_shape]).astype(np.float32)\n",
        "    interpreter.set_tensor(input_details[0]['index'], dummy_input)\n",
        "    interpreter.invoke()\n",
        "    out = interpreter.get_tensor(output_details[0]['index'])\n",
        "    print('TFLite inference output (shape):', out.shape)\n",
        "except Exception as e:\n",
        "    print('TFLite conversion/inference failed:', e)\n",
        "    print('If running locally, install or upgrade TensorFlow (>=2.4) to use TFLite converter')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. PyTorch Neural Network\n\n### Prepare Data for PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert to PyTorch tensors\n",
        "X_train_hd_s = X_train_scaled\n",
        "X_test_hd_s = X_test_scaled\n",
        "y_train_t = y_train\n",
        "y_test_t = y_test\n",
        "\n",
        "X_train_tensor = torch.FloatTensor(X_train_hd_s)\n",
        "y_train_tensor = torch.FloatTensor(y_train_t).reshape(-1, 1)\n",
        "X_test_tensor = torch.FloatTensor(X_test_hd_s)\n",
        "y_test_tensor = torch.FloatTensor(y_test_t).reshape(-1, 1)\n",
        "\n",
        "print(f'PyTorch training tensor shape: {X_train_tensor.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Build and Train PyTorch Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class PyTorchNN(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(PyTorchNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 64)\n",
        "        self.dropout1 = nn.Dropout(0.3)\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.dropout2 = nn.Dropout(0.3)\n",
        "        self.fc3 = nn.Linear(32, 1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout1(x)\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.dropout2(x)\n",
        "        x = self.sigmoid(self.fc3(x))\n",
        "        return x\n",
        "\n",
        "# Initialize model\n",
        "model_t = PyTorchNN(input_size=20)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model_t.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "model_t.train()\n",
        "epochs = 50\n",
        "for epoch in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model_t(X_train_tensor)\n",
        "    loss = criterion(outputs, y_train_tensor)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        model_t.eval()\n",
        "        with torch.no_grad():\n",
        "            test_outputs = model_t(X_test_tensor)\n",
        "            test_loss = criterion(test_outputs, y_test_tensor)\n",
        "        model_t.train()\n",
        "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}, Test Loss: {test_loss.item():.4f}')\n",
        "\n",
        "print('\\nPyTorch training completed')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Export PyTorch Model (TorchScript)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export to TorchScript\n",
        "model_t.eval()\n",
        "example_input = torch.randn(1, 20)\n",
        "traced_script_module = torch.jit.trace(model_t, example_input)\n",
        "traced_script_module.save('pytorch_model.pt')\n",
        "print('Saved PyTorch TorchScript model to pytorch_model.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === ONNX export and onnxruntime example ===\n",
        "# NEW CELL ADDED: ONNX export for cross-platform deployment\n",
        "import onnx\n",
        "import os\n",
        "\n",
        "onnx_path = 'pytorch_model.onnx'\n",
        "\n",
        "try:\n",
        "    # Create an example input (CPU) matching the model input size\n",
        "    example_input = torch.randn(1, X_train_hd_s.shape[1]).to('cpu')\n",
        "    # Ensure model is on CPU for ONNX export\n",
        "    model_t_cpu = model_t.to('cpu')\n",
        "    model_t_cpu.eval()\n",
        "\n",
        "    torch.onnx.export(\n",
        "        model_t_cpu,\n",
        "        example_input,\n",
        "        onnx_path,\n",
        "        export_params=True,\n",
        "        opset_version=11,\n",
        "        do_constant_folding=True,\n",
        "        input_names = ['input'],\n",
        "        output_names = ['output'],\n",
        "        dynamic_axes={'input' : {0 : 'batch_size'}, 'output' : {0 : 'batch_size'}}\n",
        "    )\n",
        "    print('Saved ONNX model to', onnx_path)\n",
        "\n",
        "    # Quick onnxruntime inference check (if onnxruntime installed)\n",
        "    try:\n",
        "        import onnxruntime as ort\n",
        "        sess = ort.InferenceSession(onnx_path)\n",
        "        inp_name = sess.get_inputs()[0].name\n",
        "        dummy_np = example_input.numpy().astype(np.float32)\n",
        "        res = sess.run(None, {inp_name: dummy_np})\n",
        "        print('ONNX runtime output shape:', res[0].shape)\n",
        "    except Exception as e:\n",
        "        print('onnxruntime not available or failed to run: ', e)\n",
        "        print('To run ONNX inference locally: pip install onnxruntime')\n",
        "\n",
        "except Exception as e:\n",
        "    print('ONNX export failed:', e)\n",
        "    print('Common fixes: move model to cpu and set torch.no_grad(), ensure example_input shape matches model input')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate Keras model\n",
        "keras_predictions = (model_keras.predict(X_test_scaled, verbose=0) > 0.5).astype(int).flatten()\n",
        "print('Keras Model Performance:')\n",
        "print(f'Accuracy: {accuracy_score(y_test, keras_predictions):.4f}')\n",
        "print(classification_report(y_test, keras_predictions))\n",
        "\n",
        "# Evaluate PyTorch model\n",
        "model_t.eval()\n",
        "with torch.no_grad():\n",
        "    pytorch_predictions = (model_t(X_test_tensor) > 0.5).int().numpy().flatten()\n",
        "print('\\nPyTorch Model Performance:')\n",
        "print(f'Accuracy: {accuracy_score(y_test, pytorch_predictions):.4f}')\n",
        "print(classification_report(y_test, pytorch_predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Model Deployment\n\nThis section covers exporting models for production deployment."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}